
# -*- coding: utf-8 -*-

"""
oro_grammar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s-ypAzZ7fdeqolr3kvC4Y0i0T-N7sf46

Package: oro_grammar package

----------------------------
@Author: Ebisa A. Gemechu
February 2023
----------------------------
**Project Description:**

This is a novel python package that recieves an Oromo text file from a user; extract every possible root-verbs from the text; and stores them into a python list. 
It then trims all the verbs in the list to form their corresponding list of stems. Finally, the algorithm builds their corresponding phrases using an appropriate affixation and pronouns.
The generated phrases can indicate sentence elements like, number, gender and cases.

A Python package that generates a grammar-aware Oromo phrases from the given raw text.

Input          : any Oromo document file saved as a .txt file in a directory    

	Attributes:
    in_filename  : Oromo document file saved as a .txt file
    OroStopWprds : All posible list of Oromo words in a given text,that has no significant value for word formation.
    user_text    : is a variable that stores a raw text from user input
    root_ve      : is a variable that stores the list of extracted words
		verb         : is a temporary variable to iterate over the list of root verbs
		Stem         : is a variable that stores the list of trimmed stems from the corresponding root words

  Output         : A csv file that contains a grammar-based dataset of the generated Oromp phrases 
			
"""
# Import the google drive and mount
from google.colab import drive
drive.mount('/content/gdrive')

# Import the required packages
import string

# load doc into memory
def load_doc(filename):
	# open the file as read only
	file = open(filename, 'r')
	# read all text
	text = file.read()
	# close the file
	file.close()
	return text

# turn a doc into clean tokens
def clean_doc(doc):
	# replace '--' with a space ' '
	doc = doc.replace('--', ' ')
	# split into tokens by white space
	tokens = doc.split()
	# remove punctuation from each token
	table = str.maketrans('', '', string.punctuation)
	tokens = [w.translate(table) for w in tokens]
	# remove remaining tokens that are not alphabetic
	#tokens = [word for word in tokens if word.isalpha()]
	# change to make lower case
	tokens = [word.lower() for word in tokens]
	return tokens

# save tokens to file, one dialog per line
def save_doc(lines, filename):
	data = '\n'.join(lines)
	file = open(filename, 'w')
	file.write(data)
	file.close()

# A function to accept an input from the user

# import the required liberaries
import os

path= "" 
def oro_text(path):

  """
  This function accepts the full path of an Oromo text file from the user,load the document,
  asserts if the file exists, and prints sample text.

  """

  # Accept a raw document from user with a complete file path
  in_filename = input("Enter the complete path of Oromo text as .txt file and press enter_key: \n")
  path = load_doc(in_filename)
  #Check if the file entered by the user is correctly aploaded 
  assert os.path.exists(in_filename), "I did not find the file at," + (in_filename)
  print("Bonza we found your file!")

  print("\n=>Go to 'downloads' folder to get the generated output.")
  return path

user_text= oro_text(path)

# Call the function 'clean_doc' and asign it to a variable 'word_ext'
word_ext=  clean_doc(user_text)

# Declare the necessary variables and asign values

oro_Vowels=   ['a','e','i','o','u']
verb_suffix = ['u','uu', 'uun','amu','e','ne','te','tan','an'] 

OroStopWprds= ['ani','ana','anaaf', 'kankoo','kan', 'koo','kiyya','kankiyya','anuma', 'numa','nuti','nuyi','nu','nuyiif','keenya','kankeenya',
               'keenyuma','kanumakeenya','qabu','qabna','ati','siif','kankee','kee','sihuma',"si'uma",'sima','isiniif','keessan','kankeessan',
               'isin','isuma','kanisaa','isuma','niqabdu','niqabaattu', 'niqabdan','qabdu','qabaattu','qabdan','ishee','isheedhaaf''isheef',
               'ishii','isinuma','isa','isaaf','kansaa','kanisaa','ishee','ishii','ishiif','isheedhaaf','kanishee','kanishii','isheema',
               'isheeen','wanta','wantoo','wantoota','wantoon','waan','kun','waankun','waantittiin','waantichi','waantichaaf','wantittiif',
               'waantittiima','waantichuma','waansaa','waanuma','isaan','keessan','isaaniif','isaanii','kanisaanii','isaanuma','isaanumaaf',
               'akkasi','akkana','akkanuma','akkasuma','akkasiim','maal',"waa'ee",'kam','eenyu','eenyuuf','eenyuuf','eenyuudhaaf','kana','sana',
               "ta'innaa",'laata','laata','akkasii', 'akkas','kanneen','kunniin','kkf','faan','ture','a', 'an','jira','jiraanna','qabna',
               'qabaannaa','raawwii', 'raawwataa','itti','fi','f', 'garuu','tarii','ni','san','sana','sanaan','saniin','yookin','yookiin',
               'yookis','kanaaf','kanaafuu','maaliifuu','akkuma','akkasuma','akkasumatti','akkasumaan','akkanumatti','akka','akkamalee',
               'garamalee','garmalee','akkamitti','akkamittiin','akkanattin','ammasitti','agasitti','agasittuu','oggasitti','oggasittuu',
               'agas','agasitti','agasmara','yoomillee','yoomiyyuu','illee','utuu','osoo','itti','ittiin','ittuma','ittidhiisi','ittidhiisaa',
               'dha','dhaam','wajjin','wajjinumaan','waliin','walumaan','walumatti','walumaa','walumaagalatti','dimshaashumatti',"waa'ee",
               'faallaa','dagla','gidduu','karaa','yeroo','duratti','boodatti','booda','irra','biidarra','jala','irraa','jalaa','ol','olii',
               'gadi','gara','as','asi','asii','asiif','achi','achiin','achitti','irraan','achirraan','keessa','keessatti','ala','bukkee',
               'cina','bira','biraan','bani','cufi','gararraa','gajjallaa','goda','goodaa','daka', 'amma','ammas','dabalataan','darbee',
               'yoom','eessa', 'maaliif','akkamitti','hunda','kamiyyuu','lachanuu',"tokkoon_tokkoon",'xiqqoo','tana','kana','gara','garam',
               'garas','garana','hundacaalaa','irracaalaa','caalaa','kanbiraa','biraa','muraasa','kanakka','akka',"waa'uu",'waahuu','waayyuu',
               'omaa','homaa','yookin','yookis','eeyyee','miti','lakki','lakkii','qofa','dhuunfaa','kanaaf','akkasuma','akkasumas','baayyee',
               "baa'ee","danda'a","ta'a","ta'uu",'mala','reefa','hin','ni', "ta'uuqaba", 'qaba', "nita'a","ta'innaa",'tokko',"si'a",'altokko', 
               "si'atokko","hinta'u","hintaane", "hindanda'amne","hinraawwatamne",'hinbarbaachifne','hinmilkoofne','hindagatamne','jirti',
               'jiru','jiran','dachaa','gaara','tabba','oduu','yoo','beenu','beenuu','beenaa','deemi','deemaa','yoona','yoonan','yommuu',
               'yommuun','yammuu','yammuun','yammuttii','ibsaniiru','dhiyaannu','dhaggeeffadhaa','eenyutu','eenyuun','eenyufaa','eenyuufaa',
               'eenyufaatu','fageenyan','fageenyaan','barraaye','barruu','barruun','barraaye','dabsineetu','deemame','dhageenyu','dhageenye',
               'fullaate','gufuu','guyyuu','hoggayyuu','haatahu','haatayu',"haata'u",'haatahuyyuu','haatayuyyuu',"haata'uyyuu",'hundaatiifu',
               'mootummaatitu','hinmalle','hinmalletu','halle','malle','heddu','hedduu','hedduun','hedduutu','hundaatuu','hundaattuu',
               'hundaatiifuu','hundaatuu','hundaafuu','takkaahuu','takkaiyyuu','seenaniiru','hundinuu','martinuu','inumaatuu','inumaatuu', 
               'kamiituu','keessattu','keessattuu','lachuu','loontu','lubbuu',"murtaa'e",'murtaae','taane','taate','rabsaman','tiruun',
               'tokkoon','lamaam','lamman','sadan','arfan','afran','shanan',"ja'an",'torban','saddettan','saddeettan','salgan','saglan',
               'kurnan','digdaman','soddoman','afurtaman','shantaman','jaataman','torbaataman','seddettaman','sagaltaman','dhibba','kuma',  
               'kitila','miliyoona','jabana','weedduu','weedduun','xiyyeeffame','jidduu','gidduu','jirtu','jiru','jiruu','jiran','jiruun',
               'jidduu','barbaachuu']

class Verb_extration:

  # Function to iterate over the list of words and extract root verbs from the given text file
  def root_verb(word_ext):
    next_verb = []
    for verb in word_ext:
      if verb not in OroStopWprds:
        [next_verb.append(verb) for saffix in verb_suffix if(verb[-4:] == saffix or verb[-3:] == saffix 
        or verb[-2:] == saffix or verb[-1:] == saffix)]
    return next_verb

# Extract unique root verbs into array list
root_ve= Verb_extration.root_verb(word_ext)

import numpy as np  
root_ve = list(np.unique(root_ve))
print(root_ve[:10])

# A function that that creates a.csv file, generate the data into it, and download the csv file:

"""
Create a .csv file called 'oro_auto_generated_grammar.csv' in the working directory 
and write fieldname headers in the created excel file.
"""
# import the required modules
import csv
from google.colab import files

with open('oro_auto_generated_grammar.csv', 'w', newline='', encoding ='UTF-8') as csvfile:
    fieldnames = ['Hundee |Root|', 'Jirma |Stem|','Ani |I|','Nuti |We|','Ati |You|','Isin |You|','Inni |He|','Isheen |She|','Isaan |They|']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    writer.writeheader()

    # Iterate over the list of the root verbs
    for verb in root_ve:

      # If the verb contains noun or adjective affixes, then move next
      if((verb[-2:] in ['aa','ee','ii','oo']) or verb[-3:] =='aan'or verb[:3] =='aa'or verb[-4:-1] =='aa' or
         verb[-4:] == 'dduu' or verb[-3:] =='lee'or verb[-4:] =='wwan' or verb[-7:-2] =='ummaa' or verb[-4:]
         == 'maan' or verb[-6:] =='ummaan'): 
        continue

      # Ckeck all possible conditions to trim the verbs into their stems and do the re-affixation

      elif(len(verb) > 4 and (verb[2:4] in ['ch','nn','tt'] and verb[2] != verb[3] )): 
        stem= (verb[:2] + 'dh')
      elif(len(verb) > 5 and verb[-5:-3] =='ch' and verb[-3] !='i' and verb[2] !='l'):  
        stem= (verb[:-5] + 't')
      elif(len(verb) > 4 and ( verb[-5] != 'l') and verb[-4:-2] =='ch'):  
        stem= (verb[:-4] + 't')
      elif(len(verb) > 5 and verb[-5:-1] =='eeny'):  
        stem= (verb[:-5] + "a'")
      elif(len(verb) > 6 and (verb[-4:-2] in ['dh','ny'] or verb[-3:-1] in ['dh','ny'] )):  
        stem= (verb[:-3] + 't')
      elif(len(verb) > 5 and verb[-5:-2] =='sif'):  
        stem= (verb[:-3] + 's') 
      elif(len(verb) > 5 and (verb[-5:-3] =='ft' or verb[-4:-2] =='ft') ):   
        stem= (verb[:-5] + 's')  
      elif(len(verb) > 4 and verb[-4:] in ['maan','uutu']  and verb[-5] != verb[-4]):   
        stem= verb[:-4]
      elif(verb[-4:] in ['anne','annu']):    
        stem= (verb[:-3] + 't')
      elif( len(verb) > 3 and verb[-3:] in ['uun','utu','tee','tuu'] ): #'ine',  
        stem= verb[:-3] 
      elif(verb[-4:] =='ssan'):    
        stem= verb[:-2]
      elif(verb[-3:] in ['ame','ate']):    
        stem= verb[:-1]
      elif(len(verb) > 3 and (verb[-3] in oro_Vowels) and verb[-2:] == 'te'):     
        stem= verb[:-1]  
      elif (len(verb) > 3 and verb[-2:] in ['uu','ne','te','an']): 
        stem= verb[:-2] 
      elif(len(verb) > 3 and (verb[-3] not in oro_Vowels) and (verb[-2:] in ['du','nu','re','tu'])): #and verb[2] != verb[3]    
        stem= verb[:-2] 
      else:
        stem= verb[:-1]

      # write the re-synthesized verbs into the created excel file 
      writer.writerow({'Hundee |Root|': verb, 'Jirma |Stem|':stem +'_' ,'Ani |I|': 'Ani '+ stem + 'e', 'Nuti |We|': 'Nuti '+ stem + 'ne',
                       'Ati |You|': 'Ati '+ stem +'te','Isin |You|':'Isin '+ stem + 'tan', 'Inni |He|': 'Inni '+ stem + 'e', 'Isheen |She|':
                       'Isheen '+ stem + 'te', 'Isaan |They|': 'Isaan '+ stem + 'an'})

files.download('oro_auto_generated_grammar.csv')